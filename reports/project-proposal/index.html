<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

**Project Proposal**

Student Names: Arni Bjarnsteinsson and Gianluca Figini

# Motivational Image

_The woodland village scene, featuring houses shaped like pine trees, embodies the competition theme, "The more you look,"
as it is designed to make viewers explore its intricacies.
The dynamic lighting, facilitated by Homogeneous Volumetric Participating Media and Many Lights Sampling, adds depth to the scene, ensuring that the more viewers delve into the image, the more nuances and surprises they uncover._

<img src="motivation.jpeg" alt="Motivational image" class="img-responsive">
Dan Quattrochi, Cozy Forest-dwelling village

_https://playgroundai.com/post/clf75omys06eps601hwyoxfse_ (18.11.23)

# Selected Features

## Student #1

Student Name: √Årni Bjarnsteinsson

nethz: abjarnsteins

ID      | Short Name                |Points | Features (if required) & Comments
--------|---------------------------|-------|----------------------------------
15.4    | Homogeneous Volumetric Participating Media | 15 | -
15.5    | Disney BSDF               | 15    | Specular, Roughness, Metallic, Anisotropic, Subsurface
10.10   | Mip-Mapping for texture   | 10    | -
10.5    | Low Discrepancy Sampling  | 10    | -
5.10    | Simple Emitters           | 5     | Spotlight
5.3     | Images as Textures        | 5     | -
Total   |                           | 60    |


To validate the homogeneous volumetric participating media, the spotlight and images as textures
 I will render test scenes in nori and some rendering software and do a comparison

The reason I chose these parameters for the Disney BSDF is because we'll need the specular and roughness (and color) for most materials and
on top of that we need the anisotropic for the tiles on the roofs and subsurface for the leaves. We can add some metallic materials
into the scene like lampposts which will benefit from the metallic property.
Then I will verify either using https://github.com/wdas/brdf or by doing an image comparison.

For the Mip-mapping I will verify by doing a performance comparison, with and without on top of a correctness check by an image comparison.

And finally for the Low discrepancy sampling I will both compute the D* discrepancy for the samples generated and compare the noise of some images
generated using a fixed amount of samples.



## Student #2

Student Name: Gianluca Figini

nethz: gfigini

ID      | Short Name                |Points | Features (if required) & Comments
--------|---------------------------|-------|----------------------------------
30.5    | Many lights sampling      | 30    | -
10.8    | Resampled Importance Sampling (RIS) | 10 | -
5.20    | Modeling Meshes           | 5     | -
5.19    | Rendering on the cluster  | 5     | -
5.17    | Object instancing         | 5     | -
5.7     | Intel's Open Image Denoise| 5     | -
Total   |                           | 60    |

To validate the many lights sampling, I will compareimages rendered with and without this addition. A wrong implementation of this feature is likely to create unwanted shadows and highlights. On the other hand, if the implementation was correct, we should observe a decreased level of noise in the final reder.

Resampled Importance Sampling aims to reduce noise and improve convergence by allocating more samples to important regions. To validate this feature, I will compute the variance in the image, or in other simpler scenes. I expect this to be significantly smaller than in the case where RIS is not used. For some specific scenes, specialized test cases could be created.


To validate the features of object instancing and mesh modeling, I will ensure that the generated mesh aligns with the intended design. Additionally, for the Euler cluster and Intel denoising features, my validation process will focus on confirming the operational functionality and verifying that these systems perform as expected.




# Supplementary
* This report template uses [Markdeep](https://casual-effects.com/markdeep/), which supports Markdown syntax in HTML file. For example usage, please refer to the [official demo document](https://casual-effects.com/markdeep/features.md.html).

* LaTeX is also supported for typing mathematical formulas:
$$
L_o(\mathbf{x}, \omega_o) = \int_{\Omega} L_i(\mathbf{x},\omega_i)\, f(\mathbf{x}, \omega_i, \omega_o)\, |\cos\theta_i|\, \mathrm{d}\omega_i
$$



<!-- Bootstrap core CSS and JavaScript -->

<link href="../resources/offcanvas.css" rel="stylesheet">
<link href="../resources/twentytwenty.css" rel="stylesheet" type="text/css" />

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="../resources/bootstrap.min.js"></script>
<script src="../resources/jquery.event.move.js"></script>
<script src="../resources/jquery.twentytwenty.js"></script>

<script>
    $(window).load(function () { $(".twentytwenty-container").twentytwenty({ default_offset_pct: 0.5 }); });
</script>

<!-- Markdeep: -->
<script>var markdeepOptions = { onLoad: function () { $(".twentytwenty-container").twentytwenty({ default_offset_pct: 0.5, move_slider_on_hover: true }); }, tocStyle: 'none' };</script>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<script>window.alreadyProcessedMarkdeep || (document.body.style.visibility = "visible")</script>

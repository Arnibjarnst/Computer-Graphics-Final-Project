<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

**Homework 1 - Getting Started**

Student Name: Árni Bjarnsteinsson

Legi Number: 21-907-241

(Note: please read the [supplementary](#supplementary) section first before working on this report.)

# Part 1: Normal Integrator
**Time spent on this task: 1 hour**

**Describe your implementation of Normal Integrator.**
The time spent was mostly in setting up Nori and not creating the integrator since it is provided on the website.
"My" implementation checks if the ray has an intersection, if it does return component-wise absolute value of the intersecting points shading normal, else return a black.



**Shading Normal Comparison: Ajax**
<div class="twentytwenty-container">
    <img src="images/ajax-normals-ref.png" alt="Reference" class="img-responsive">
    <img src="images/ajax-normals.png" alt="Mine" class="img-responsive">
</div>



# Part 2: Average Visibility Integrator
**Time spent on this task: 2-3 hours (2 hours were wasted cause I misunderstood the definition)**

**Describe your implementation of Average Visibility Integrator.**
My implementation checks for an intersection, returns white if no intersection is found. Else I sample a vector on the shading normals hemisphere
then I shoot a ray in that direction and check if it hits anything before t distance. If it does, I return black else white.
(the ray makes sure to not hit anything before some epsilon to avoid self collission)

**Average Visibility Comparison: Ajax**
<div class="twentytwenty-container">
    <img src="images/ajax-av-ref.png" alt="Reference" class="img-responsive">
    <img src="images/ajax-av.png" alt="Mine" class="img-responsive">
</div>

**Average Visibility Comparison: Sponza**
<div class="twentytwenty-container">
    <img src="images/sponza-av-ref.png" alt="Reference" class="img-responsive">
    <img src="images/sponza-av.png" alt="Mine" class="img-responsive">
</div>



# Part 3: Analytic Sphere Shape
**Time spent on this task: 3 hours**

**Describe your implementation of Sphere and two functions.**
I needed to implement 2 functions, one to check if there is an intersection and find how far along the ray it is (if there is one) and one to calculate more information about the intersection.
The intersection test function simply solves the linear programming problem of a line and a circle intersecting where our line is the line along the ray.
Instead of calculating both intersections I calculate the first one since we want the first intersection and if it is in the range of [ray.mint;ray.maxt] then I return true.
Else I calculate the other intersection and do the same check. This only needed if the ray origin is inside the circle since then we don´t want a negative t.

I also had to set hit information for the sphere intersection. I simply find the direction from the center of my sphere to the intersection point and use that as both the geometric and shading frame normal.
Then I calculate the uv coordinates where I had to implement my own way of calculating the spherical coordinates and scale them to fit [0;1]. (the time spent on the last part is counted part 5)


**Sphere Analytic vs Mesh Comparison**
<div class="twentytwenty-container">
    <img src="images/sphere-analytic-ref.png" alt="Reference" class="img-responsive">
    <img src="images/sphere-analytic.png" alt="Mine" class="img-responsive">
    <img src="images/sphere-mesh-ref.png" alt="Reference" class="img-responsive" class="img-responsive">
    <img src="images/sphere-mesh.png" alt="Mine" class="img-responsive" class="img-responsive">
</div>



# Part 4: Direct Illumination Integrator
**Time spent on this task: 10 hours**

**Describe your implementation of Direct Illumination Integrator.**

For this I needed to implement 2 things, a point light and a direct illumination integrator.

For the pointlight we want to find the amount of energy that reaches a certain point which is the power of the light divided by the area of a sphere since the pointlight is only a single point and therefore distributes energy equally in all directions.
We also would like to fill in a bit of extra information here such as the incdent vector and the shadow ray since they can be used in the integrator.

For the integrator I first check if the ray hits anything, if not return black. Else I get the BSDF of that intersection point and all the lights in the scene.
Then for every light I calculate the power that reaches that point from the light (assuming there is nothing inbetween the light and the point). then I calculate the cosine between the incident ray and the shading normal (cosine * power) is the amount of power that actually reaches the plane.
I also check if the cosine is negative which means that the light is behind the plane and therefore cannot reach it. Then I shoot the shadow ray back to check if the point is occluded or not. If it isn´t the I query the bsdf and multiply that with the cosine * power from before which is the total color that comes from that light source to the camera.
Finally I sum up all the values from all the lights and return that.

**Direct Illumination Comparison: Sponza**
<div class="twentytwenty-container">
    <img src="images/sponza-direct-ref.png" alt="Reference" class="img-responsive">
    <img src="images/sponza-direct.png" alt="Mine" class="img-responsive">
</div>



# Part 5: Texture Mapping
**Time spent on this task: 5 hours**

**Describe your implementation of texture mapping.**

the checkerboard texture map simply takes the uv coordinates, divides them by the scaling factor and subtracts the offset. Then I round those values down to get the discrete coordinates i and j in the units of checkerboard squares.
Since this is a checkerboard texture, and 0,0 is m_value1 we will have m_value1 iff i and j are either both even or both odd => (i+j) is even. I therefore check (i+j)%2 and return the appropriate value.


**Checkerboard Comparison: Sphere**
<div class="twentytwenty-container">
    <img src="images/sphere-texture-ref.png" alt="Reference" class="img-responsive">
    <img src="images/sphere-texture.png" alt="Mine" class="img-responsive">
</div>

**Checkerboard Comparison: Mesh**
<div class="twentytwenty-container">
    <img src="images/mesh-texture-ref.png" alt="Reference" class="img-responsive">
    <img src="images/mesh-texture.png" alt="Mine" class="img-responsive">
</div>



# Feedback
**Use this section to provide feedback about this assignment (each task, the handout, Nori, etc.). We appreciate your opinions to help improve future homeworks and projects.**

I think the description for the offset and scale in part 5 is incorrect. If (m_delta + eps) is supposed to be the origin of the checkerboard and we want to transform the uv coordinates into the unit distances of m_scale.
If we scale back first and then shift we will get m_delta / m_scale - m_delta which is not always 0. however if we do it the other way around we get 0.

I probably spent around 3 hours trying to fix my code because the spherical_coordinates function in the codebase does not output the required format to produce the reference image.


# Supplementary
* For each task, please note down the time you spent working through it and use at least a few sentences to describe your implementation. If applicable, also report the problems you encounter (e.g. whether or how it's solved, what is the difficult part).

* Please let us know to what extent your code is working (e.g. you only managed to work through part of this assignment, or your solution doesn't operate as expected in some corner cases). We encourage you to share your thinking process, and points will be granted based on your description even if the code is not 100% functioning.

* Nori generates both EXR and PNG format output. Please use PNG for image comparison in the report.

* This report template uses [Markdeep](https://casual-effects.com/markdeep/), which supports Markdown syntax in HTML file. For example usage, please refer to the [official demo document](https://casual-effects.com/markdeep/features.md.html).

* LaTeX is also supported for typing mathematical formulas:
$$
L_o(\mathbf{x}, \omega_o) = \int_{\Omega} L_i(\mathbf{x},\omega_i)\, f(\mathbf{x}, \omega_i, \omega_o)\, |\cos\theta_i|\, \mathrm{d}\omega_i
$$



<!-- Bootstrap core CSS and JavaScript -->

<link href="../resources/offcanvas.css" rel="stylesheet">
<link href="../resources/twentytwenty.css" rel="stylesheet" type="text/css" />

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="../resources/bootstrap.min.js"></script>
<script src="../resources/jquery.event.move.js"></script>
<script src="../resources/jquery.twentytwenty.js"></script>

<script>
    $(window).load(function () { $(".twentytwenty-container").twentytwenty({ default_offset_pct: 0.5 }); });
</script>

<!-- Markdeep: -->
<script>var markdeepOptions = { onLoad: function () { $(".twentytwenty-container").twentytwenty({ default_offset_pct: 0.5, move_slider_on_hover: true }); }, tocStyle: 'none' };</script>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<script>window.alreadyProcessedMarkdeep || (document.body.style.visibility = "visible")</script>
